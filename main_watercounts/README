########################################### WATERCOUNTS ####################################################
######## Jaime Medina
######## Weill Cornell Medical College, Rockefeller University
######## August 2014
############################################################################################################


This is a very preliminary version of the code. It works and it is relatively user-friendly. 
Many things can be modified in order to facilitate the input of the data or the results for particular cases. 



PACKAGE CONTENTS

Files
- run_watercounts.sh:	executable file in which some parameters have to be set. The program will be run by 
			calling sh run_watercounts.sh
- aux_parallel.sh:	auxiliary file. There is no need to modify it

Folders
- protein:		folder with a random psf and dcd files to execute the example. Not needed at all
- scripts:		contains the VMD and R auxiliary files to run and plot the results repectively. 
			It needs to be placed as ./scripts, as in this example
- sites:		folder containing the tcl scripts that define the water molecules to look for. 
			Also under the main folder, in ./sites

Two additional folders will be created under the main folder when running the code
- watercounts:		the results will be written in watercounts/data. If the plotting code is executed the 
			plots will be placed in watercounts.plots
- logs:			it keeps the log files of VMD when it is run. Important to find errors



PARAMETERS

The program will read the psf and dcd files, the identifier of the specific results and the site in which you 
want to count the waters
The output will be a .dat file in ./watercounts/data/ named watercounts_site_name.dat
This things are defined at the beginning of run_watercounts.sh

- name:			name that the output file will contain in its name
- psf:			relative or absolute path to the psf file
- dcd:			relative or absolute path to the dcd file
- sites:		sites that you want to analyse when running the code. They should be written between ()
			 and separated by spaces, as in the example

- size:			the counting will be calculated in different parts, each of them will analyse this 
			number of frames (S)
- memory:		amount of memory that the submitted job will ask for when it is submitted. The lower the 
			memory requested, the less time it will spend in the queue

- vmd:			relative or absolute path to vmd in your machine
- catdcd:		relative or absolute path to catdcd in your machine



DEFINITION OF THE SITES

Many different sites to look for water in can be defined at the same time. 
To define a new site you need to create a new file with the name of the site that will be written in the name of 
the output file with .tcl extension. In our example IC_cav.tcl stands for intracellular cavity
That file will describe which water molecules should be counted in each frame in tcl language.
You can write as many lines as you want to define it, with any intermediate selection you may need
That final atomselection should be called waterbasicsel and DO NOT FORGET to add frame $f in the end, as in the example
Keep every site you define in that folder. In the line sites of run_watercounts.sh you can write which ones you
want to analyze, as stated before

To make the final selection we recommend to visually inspect our dcd file in VMD and arbitrarily choose some easy
parameters to define the volume we are interested in. Then there will be many molecules in different frames that 
technically will fit that definition but we don't want them in the analysis. Add many different lines to prevent them
to be counted (for example you can add 'and not within 5 of (protein and resid 34)' until you are mostly satisfies 
with the result.



WORKFLOW

Once you create the file for the site you want to analyze and fill the six parameters at the beginning 
of run_watercounts.sh you are ready to start
This is what will happen when you type sh run_watercounts.sh from the main folder. It is very important that 
you understand it in order to make particullar modifications in the future

- The parameters are read and the watercounts and logs folders are created
- catdcd counts the number of total frames (F) in the dcd file
- The number of jobs in which the dcd file will be divided (n) is calculated. Each of them will analyse a number
  of frames given in size. For example, if size=100 and F=4321, 44 jobs would be submitted: the first one would
  analyze 1-100, the second one 101-200...
- n jobs will be submitted for each site defined in sites. In summary, each job will analyse one site and one
  set of frames of the size previously defined. Each job will request for the memory given at the beginning

Tasks performed but each job separately
- The first and the last frame to analyse will be identified according to the index of the array-job. 
- VMD will run the script for counting the waters in those frames for that specific site and will save
  it as watercounts_site_name_partXXXXX.dat
- When n files have been created the results are merged together in the same file and the 'part' files are deleted.
- Same thing is done with the VMD log files: they are merged together and the 'part' logs are deleted.



POSSIBLE MODIFICATIONS

As stated before, this example is designed to be very descriptive and simple. Many little modifications can be added
that may simplify its application

- If you have several psf and dcd files in the main folder (under symbolic links, for example) you may prefer to
  introduce the psf and dcd files path from the command line. For that just change those lines to 
  - psf=$1
  - dcd=$2
  and call run_watercounts.sh as sh run_watercounts.sh yourpsf yourdcd
- A variation of this would be if you want to run different runs of the same protein. In the psf and dcd lines you
  can leave part of the names depending on the command line arguments as $1. Then you could execute the code
  as sh run_watercounts.sh 23, for example
- We recommend to think of how to write the name of the identifier of the results. If you are running several runs of
  each protein it would be more logical to write in all of them the name of the protein before the number of the run.
  Therefore, the results will be listed in alphabetical order and your results will be grouped with each protein separately
- By default the jobs are submitted with the name qwaterparallel. You may want to distinguish them in the queue by an
  identifiable name, as its site and name. You can do that by deleting the line '#$ -N qwaterparallel' in aux_parallel.sh
  and adding -N q$site$name in the line of run_watercounts.sh that submits the job
- By default the output files from the submitted jobs are deleted. If you don't want them to be deleted, name them with
  a name that does not start with q or comment the line that removes them at the beginning of aux_parallel.sh
- By default the number of the parts is written in a 5 digit format. This is important to cat the results in the proper
  order when the part files are merged. If you divide your dcd files in more jobs (n>100000) change the 5 in the 
  line 'i=`printf "%05d" $i`' of aux_parallel.sh by a bigger number
- 1GB of memory is enough for 100 frames of a 140,000 atoms simulation. Try to keep it always as low as possible, they will
  wait less time in the queue and you will not waste resources



ANNEX: PLOT THE RESULTS

A sample code to plot the results is provided. It's not worth to explain it because every case will need different
plotting tools, but it will probably be a good starting point. To execute it, go to the main folder and write
Rscript scripts/plot.R or source it in R with the working directory set in the main folder. You can see the output
in watercounts/plots/

